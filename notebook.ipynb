{"cells":[{"cell_type":"markdown","metadata":{"id":"YVPEo1caCdj7"},"source":["# CMU Deep Learning Systems Course (Online)\n","### Final project by Dmitry Sholomitsky and Lubov Kudrenok\n","\n","Proposal:\n","> Model save/load functionality; transformers architecture blocks, including classes like Attention, MultiheadAttention, Transformer.\n","\n","Implemetations *(briefly)*:\n","\n","1. Transformers architecture:\n","\n","    * `needle/transformers.py` - new module:\n","        * `TransformerEncoder`\n","        * `TransformerEncoderLayer`\n","        * `MultiheadAttention`\n","    * `needle/tokenizers.py` - new module:\n","        * `Tokenizer` - base class for tokenizers;\n","        * `EngLemmaTokenizer` - tokenizer for English language with lemmatization;\n","    * `needle/ops.py` - added new functions:\n","        * `softmax`\n","        * `bmm` - function for batch matrix multiplication;\n","    * `needle/data.py` - some minor upgrades:\n","        * `DataLoader` - added `__len__` method; method `__next__` now puts data on device if provided;\n","\n","2. Save/load functionality:\n","\n","    * `needle/backend_ndarray/ndarray.py` - upgrades:\n","        * `BackendDevice` - added methods `__getstate__` and `__setstate__` to make it `pickle`-able;\n","        * `NDArray` - added methods `__getstate__` and `__setstate__` to make it `pickle`-able;\n","    * `needle/utils.py` - new module:\n","        * `save` - new function to save `needle` object;\n","        * `load` - new function to load `needle` object.\n","\n","More detailed information will be provided further in the notebook.\n","\n","Repository with source code: https://github.com/dmitry-rvn/CMUDLS_project.git"]},{"cell_type":"markdown","metadata":{"id":"-yVc47oR-zU4"},"source":["## 0. Preparations"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2106,"status":"ok","timestamp":1672835041538,"user":{"displayName":"Дмитрий Шоломицкий","userId":"05073812129486018670"},"user_tz":-180},"id":"L35BiRJZ9jtk","outputId":"0b3bb9bb-7fc1-4cfd-82cb-4ab15050ebed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'CMUDLS_project'...\n","remote: Enumerating objects: 33, done.\u001b[K\n","remote: Counting objects: 100% (33/33), done.\u001b[K\n","remote: Compressing objects: 100% (30/30), done.\u001b[K\n","remote: Total 33 (delta 0), reused 33 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (33/33), done.\n"]}],"source":["! git clone https://github.com/dmitry-rvn/CMUDLS_project.git"]},{"cell_type":"markdown","metadata":{"id":"SIR2xGlgB_nl"},"source":["In case of `gdown` not working, data is available with links: https://drive.google.com/file/d/1Nodv3EaqGe8jaUvSXAEAek0NlSgf9Fdr/view?usp=share_link or https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3333,"status":"ok","timestamp":1672835048478,"user":{"displayName":"Дмитрий Шоломицкий","userId":"05073812129486018670"},"user_tz":-180},"id":"-avoEMBSBe6w","outputId":"555f5977-3a1f-4dbf-8a1c-615ee71d82df"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1Nodv3EaqGe8jaUvSXAEAek0NlSgf9Fdr&confirm=t\n","To: /content/IMDB_Dataset.csv.zip\n","100% 27.0M/27.0M [00:01<00:00, 25.9MB/s]\n"]}],"source":["! gdown \"1Nodv3EaqGe8jaUvSXAEAek0NlSgf9Fdr&confirm=t\""]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38998,"status":"ok","timestamp":1672835087469,"user":{"displayName":"Дмитрий Шоломицкий","userId":"05073812129486018670"},"user_tz":-180},"id":"-RwX7vUNBMt2","outputId":"19879c5e-f8f3-4219-e4ac-1d9b999ef64f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/CMUDLS_project/project\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pybind11\n","  Downloading pybind11-2.10.3-py3-none-any.whl (222 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.4/222.4 KB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting loguru\n","  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (3.4.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.25.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.10)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.21.6)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.4)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (6.3.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.8)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.7)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (8.1.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy) (57.4.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.11.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.9)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (21.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.10.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.8)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.7.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.3.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.4.5)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy) (2.0.1)\n","Installing collected packages: pybind11, loguru\n","Successfully installed loguru-0.6.0 pybind11-2.10.3\n","-- The C compiler identification is GNU 7.5.0\n","-- The CXX compiler identification is GNU 7.5.0\n","-- Detecting C compiler ABI info\n","-- Detecting C compiler ABI info - done\n","-- Check for working C compiler: /usr/bin/cc - skipped\n","-- Detecting C compile features\n","-- Detecting C compile features - done\n","-- Detecting CXX compiler ABI info\n","-- Detecting CXX compiler ABI info - done\n","-- Check for working CXX compiler: /usr/bin/c++ - skipped\n","-- Detecting CXX compile features\n","-- Detecting CXX compile features - done\n","-- Found Python: /usr/bin/python3.8 (found version \"3.8.16\") found components: Development Interpreter Development.Module Development.Embed \n","-- Performing Test HAS_FLTO\n","-- Performing Test HAS_FLTO - Success\n","-- Found pybind11: /usr/local/lib/python3.8/dist-packages/pybind11/include (found version \"2.10.3\")\n","-- Looking for pthread.h\n","-- Looking for pthread.h - found\n","-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n","-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed\n","-- Looking for pthread_create in pthreads\n","-- Looking for pthread_create in pthreads - not found\n","-- Looking for pthread_create in pthread\n","-- Looking for pthread_create in pthread - found\n","-- Found Threads: TRUE  \n","-- Found CUDA: /usr/local/cuda (found version \"11.2\") \n","-- Found cuda, building cuda backend\n","NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n","\n","-- Configuring done\n","-- Generating done\n","-- Build files have been written to: /content/CMUDLS_project/project/build\n","make[1]: Entering directory '/content/CMUDLS_project/project/build'\n","make[2]: Entering directory '/content/CMUDLS_project/project/build'\n","make[3]: Entering directory '/content/CMUDLS_project/project/build'\n","make[3]: Leaving directory '/content/CMUDLS_project/project/build'\n","make[3]: Entering directory '/content/CMUDLS_project/project/build'\n","[ 25%] \u001b[32mBuilding CXX object CMakeFiles/ndarray_backend_cpu.dir/src/ndarray_backend_cpu.cc.o\u001b[0m\n","[ 50%] \u001b[32m\u001b[1mLinking CXX shared module ../python/needle/backend_ndarray/ndarray_backend_cpu.cpython-38-x86_64-linux-gnu.so\u001b[0m\n","make[3]: Leaving directory '/content/CMUDLS_project/project/build'\n","[ 50%] Built target ndarray_backend_cpu\n","make[3]: Entering directory '/content/CMUDLS_project/project/build'\n","[ 75%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/ndarray_backend_cuda.dir/src/ndarray_backend_cuda_generated_ndarray_backend_cuda.cu.o\u001b[0m\n","nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n","nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n","make[3]: Leaving directory '/content/CMUDLS_project/project/build'\n","make[3]: Entering directory '/content/CMUDLS_project/project/build'\n","[100%] \u001b[32m\u001b[1mLinking CXX shared module ../python/needle/backend_ndarray/ndarray_backend_cuda.cpython-38-x86_64-linux-gnu.so\u001b[0m\n","make[3]: Leaving directory '/content/CMUDLS_project/project/build'\n","[100%] Built target ndarray_backend_cuda\n","make[2]: Leaving directory '/content/CMUDLS_project/project/build'\n","make[1]: Leaving directory '/content/CMUDLS_project/project/build'\n"]}],"source":["%cd /content/CMUDLS_project/project\n","! pip3 install pybind11 loguru tqdm spacy\n","! make"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c2wr4FIEwsKz"},"outputs":[],"source":["import sys\n","sys.path.append('./python')\n","\n","import os\n","os.environ['NEEDLE_BACKEND'] = 'nd'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ixq9mrzNvw69"},"outputs":[],"source":["from typing import List, Tuple\n","import warnings\n","\n","import torch\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from tqdm.notebook import tqdm\n","from loguru import logger\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import needle as ndl\n","from needle import nn\n","from needle import optim\n","from needle import ops\n","from needle.data import Dataset, DataLoader\n","\n","from needle.transformers import TransformerEncoder\n","from needle.tokenizers import Tokenizer, EngLemmaTokenizer\n","\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","source":["logger.add('/content/logs/log.txt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3XhavMvcSHce","executionInfo":{"status":"ok","timestamp":1672762286435,"user_tz":-180,"elapsed":15,"user":{"displayName":"Дмитрий Шоломицкий","userId":"05073812129486018670"}},"outputId":"afd753bd-dc2f-4c8a-dee8-08571ebbf69a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uRUeZ7MFxaoc"},"outputs":[],"source":["DATA_FILEPATH = '/content/IMDB_Dataset.csv.zip'\n","\n","MAX_VOCAB_SIZE = 10_000\n","MAX_LENGTH = 128\n","\n","BATCH_SIZE = 20\n","\n","EPOCHS = 1\n","LEARNING_RATE = 0.001\n","WEIGHT_DECAY = 0.0"]},{"cell_type":"code","source":["if torch.cuda.is_available():\n","    DEVICE = ndl.backend_ndarray.cuda()\n","else:\n","    DEVICE = ndl.backend_ndarray.cpu()\n","logger.info(f'DEVICE: {DEVICE}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"le0lfSUdJ8Xq","executionInfo":{"status":"ok","timestamp":1672762287431,"user_tz":-180,"elapsed":6,"user":{"displayName":"Дмитрий Шоломицкий","userId":"05073812129486018670"}},"outputId":"09b87547-e3db-4ca7-be3e-c2b634fbfcdc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2023-01-03 16:11:25.958 | INFO     | __main__:<module>:5 - DEVICE: cuda()\n"]}]},{"cell_type":"markdown","metadata":{"id":"mVP-jvZpXeV0"},"source":["## 1. Data\n","\n","In order to prove that model with our architecture actually works, we will try to train it on this data for text classification from https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews (movie reviews with label either 'positive' or 'negative')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":979,"status":"ok","timestamp":1672762288406,"user":{"displayName":"Дмитрий Шоломицкий","userId":"05073812129486018670"},"user_tz":-180},"id":"6DPO11XWvw1l","outputId":"54d040c9-080b-4015-bc24-c505725aaa6e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  review sentiment\n","20330  That's about the only redeeming quality in a m...  negative\n","17532  Even if I had not read Anne Rice's \"Queen of t...  negative\n","45819  I sort of liked this Columbo movie its atmosph...  positive\n","34807  \"Zabriskie Point\" (1970): This was especially ...  positive\n","31888  Quite one of the worst films I have ever seen....  negative\n","...                                                  ...       ...\n","21243  I did not set very high expectations for this ...  positive\n","45891  THE BLOB is a great horror movie, not merely b...  positive\n","42613  After too many years of waiting, Anne Rivers S...  positive\n","43567  I am a massive fan of the LoG. I thought the f...  negative\n","2732   AG was an excellent presentation of drama, sus...  positive\n","\n","[40000 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-d2e5242f-ef8e-437b-ae4d-8fb05b4e7ca6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>20330</th>\n","      <td>That's about the only redeeming quality in a m...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>17532</th>\n","      <td>Even if I had not read Anne Rice's \"Queen of t...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>45819</th>\n","      <td>I sort of liked this Columbo movie its atmosph...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>34807</th>\n","      <td>\"Zabriskie Point\" (1970): This was especially ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>31888</th>\n","      <td>Quite one of the worst films I have ever seen....</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>21243</th>\n","      <td>I did not set very high expectations for this ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>45891</th>\n","      <td>THE BLOB is a great horror movie, not merely b...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>42613</th>\n","      <td>After too many years of waiting, Anne Rivers S...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>43567</th>\n","      <td>I am a massive fan of the LoG. I thought the f...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2732</th>\n","      <td>AG was an excellent presentation of drama, sus...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>40000 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2e5242f-ef8e-437b-ae4d-8fb05b4e7ca6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d2e5242f-ef8e-437b-ae4d-8fb05b4e7ca6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d2e5242f-ef8e-437b-ae4d-8fb05b4e7ca6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}],"source":["data = pd.read_csv(DATA_FILEPATH)\n","data['review'] = data['review'].str.replace('<br />', ' ')\n","data_train, data_test = train_test_split(data, test_size=0.2, random_state=0)\n","data_train"]},{"cell_type":"markdown","metadata":{"id":"nddtVgCEXwAy"},"source":["Since data is balanced we will use `accuracy_score` further to evaluate classification quality:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1672762288406,"user":{"displayName":"Дмитрий Шоломицкий","userId":"05073812129486018670"},"user_tz":-180},"id":"QZRp69bGXstb","outputId":"e8fb86ad-f345-48a0-b5bf-d314382d90c7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["positive    25000\n","negative    25000\n","Name: sentiment, dtype: int64"]},"metadata":{},"execution_count":10}],"source":["data['sentiment'].value_counts()"]},{"cell_type":"code","source":["class IMDB50kReviews(Dataset):\n","    def __init__(self, data: pd.DataFrame, tokenizer: Tokenizer, max_length: int = None):\n","        super().__init__()\n","        self.label2index = {'positive': 1, 'negative': 0}\n","        self.index2label = {idx: label for label, idx in self.label2index.items()}\n","        data = data.copy()\n","        data['sentiment'] = data['sentiment'].map(self.label2index)\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","        self.num_classes = len(self.label2index)\n","\n","    def __getitem__(self, item):\n","        text = self.data.iloc[item]['review']\n","        label = self.data.iloc[item]['sentiment']\n","\n","        indices = []\n","        if isinstance(text, str):\n","            text = [text]\n","            label = [label]\n","        for text_ in text:\n","            indices.append(self.tokenizer(text_, max_length=self.max_length))\n","        return np.array(indices), np.array(label)\n","\n","    def __len__(self):\n","        return len(self.data)"],"metadata":{"id":"ipEKkHQs8U9A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jD0IzfjHY6aH"},"source":["## 2. Tokenizer\n","\n","In order to learn token embeddings, we need to create a tokenizer that get text input and returns list of token indices. It needs fitting on train data to create vocabulary.\n","\n","In `needle/tokenizers.py` we created:\n","* `Tokenizer` - base class for tokenizers;\n","* `EngLemmaTokenizer` - tokenizer for English language, that\n","    * removes punctuation\n","    * applies lemmatization with `spacy` (+ lowering)\n","    * adds start-of-sequence and end-of-sequence tokens\n","    * performs truncation and padding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0u4Bacj4ZVUg"},"outputs":[],"source":["tokenizer = EngLemmaTokenizer(max_vocab_size=MAX_VOCAB_SIZE).fit(data_train['review'].tolist())"]},{"cell_type":"markdown","source":["Example of tokenizer usage:"],"metadata":{"id":"NARLolPKNvno"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1672762685902,"user":{"displayName":"Дмитрий Шоломицкий","userId":"05073812129486018670"},"user_tz":-180},"id":"4o2JbVLHImUj","outputId":"ea75864f-13c7-40cb-feb3-8afb70d8eccb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenizer size: 10004\n","Default tokens: {'<UNK>': 0, '<PAD>': 1, '<SOS>': 2, '<EOS>': 3}\n","\n","Phrase to tokenize: How are you, NotARealName?\n","Token ids with max_length=None: [2, 90, 27, 23, 0, 3]\n","Token ids with max_length=5   : [2, 90, 27, 23, 3]\n","Token ids with max_length=10  : [2, 90, 27, 23, 0, 3, 1, 1, 1, 1]\n"]}],"source":["print(f'Tokenizer size: {len(tokenizer)}')\n","print(f'Default tokens: {tokenizer.default_tokens}\\n')\n","\n","phrase_to_tokenize = 'How are you, NotARealName?'\n","print(f'Phrase to tokenize: {phrase_to_tokenize}')\n","for max_length in (None, 5, 10):\n","    token_ids = tokenizer(phrase_to_tokenize, max_length=max_length)\n","    print(f'Token ids with max_length={str(max_length): <4}: {token_ids}')"]},{"cell_type":"markdown","source":["## 3. `Dataset`s and `DataLoader`s\n","\n","We've added to `needle.data.DataLoader` `__len__` method (for more convenient usage with `tqdm`), and `__next__` method now puts data on the device if provided."],"metadata":{"id":"PEnPaVIq8x6I"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BvRkf104ImXD"},"outputs":[],"source":["train_dataset = IMDB50kReviews(data_train, tokenizer, max_length=MAX_LENGTH)\n","valid_dataset = IMDB50kReviews(data_test, tokenizer, max_length=MAX_LENGTH)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CDcQhxUdvwj6"},"outputs":[],"source":["train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, device=DEVICE, random_seed=0)\n","valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, device=DEVICE)"]},{"cell_type":"markdown","metadata":{"id":"H1wloWoaRXP_"},"source":["Check shapes, devices, values:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":597,"status":"ok","timestamp":1672762686479,"user":{"displayName":"Дмитрий Шоломицкий","userId":"05073812129486018670"},"user_tz":-180},"id":"5LQiZWIARJ8P","outputId":"29ab9909-a3c3-4033-8ea1-55d94cdfcbd3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((20, 128), cuda(), (20,), cuda())"]},"metadata":{},"execution_count":16}],"source":["batch_x, batch_y = next(iter(train_dataloader))\n","batch_x.shape, batch_x.device, batch_y.shape, batch_y.device"]},{"cell_type":"code","source":["np.array(batch_x.numpy()[4], dtype=int)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dz7jk1DS_jM5","executionInfo":{"status":"ok","timestamp":1672762686481,"user_tz":-180,"elapsed":28,"user":{"displayName":"Дмитрий Шоломицкий","userId":"05073812129486018670"}},"outputId":"94d9b317-9b43-4171-a1cc-a91aa09e9941"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([   2,   12,   65,  299,   13,   22,   40,  462,    8,  133,   88,\n","         12, 4780,    6,  427,   12,   63,   10, 1552,   60, 3912,  717,\n","       1108,   14,  111,   79,  108,   30,   10,  203,   32,    4,  247,\n","         22,   12,   30,  126,  110,   12,  140,  776,    6,    0,  276,\n","         69,  383,   24,   10,    3,    1,    1,    1,    1,    1,    1,\n","          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","          1,    1,    1,    1,    1,    1,    1])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["batch_y.numpy()[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ktmN9AJ2CJY0","executionInfo":{"status":"ok","timestamp":1672762686481,"user_tz":-180,"elapsed":21,"user":{"displayName":"Дмитрий Шоломицкий","userId":"05073812129486018670"}},"outputId":"25efabc3-c8f0-488c-d89f-d218de146922"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 1., 0., 0., 1., 1., 0., 1.], dtype=float32)"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"y7QiUUPeSPP7"},"source":["## 4. Model\n","\n","In order to check adequacy of our Transformer implementation we created model with Transformer as **encoder** and **classification head** to classify movie reviews.\n","\n","Transformer architecure implemented in `needle/transformer.py` with 3 classes:\n","* `TransformerEncoder` - it includes token and position embeddings and number of `TransformerEncoderLayer`;\n","* `TransformerEncoderLayer` - it has `MultiheadAttention` and other components like `LayerNorm`s and `Linear`s;\n","* `MultiheadAttention` - it has *query*, *key*, *value* and *out* weights, applies `softmax` and other operations.\n","\n","For some reason, Colab does not want to render our scheme (diagram) of our Transformer implementation (here we draw every operation in `forward` methods), so please check it with this link: https://github.com/dmitry-rvn/CMUDLS_project/blob/main/assets/transformer-schema.png\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQc-jZCvHCxE"},"outputs":[],"source":["class TextClassifier(nn.Module):\n","    def __init__(self, \n","                 num_classes: int,\n","                 vocab_size: int,\n","                 transformer_hidden_dim: int, \n","                 transformer_linear_dim: int, \n","                 transformer_n_layers: int,\n","                 transformer_n_heads: int,\n","                 transformer_max_length: int,\n","                 clf_linear_dim: int, \n","                 dropout: float = 0.2,\n","                 device=None):\n","        # our implementation of Transformer encoder\n","        self.encoder = TransformerEncoder(\n","            input_dim=vocab_size, \n","            max_length=transformer_max_length,\n","            hidden_dim=transformer_hidden_dim,\n","            feed_forward_dim=transformer_linear_dim,\n","            n_layers=transformer_n_layers, \n","            n_heads=transformer_n_heads, \n","            dropout=dropout, \n","            device=device\n","        )\n","        # classification head to map start-of-sequence embeddings to classes logits\n","        self.classificator = nn.Sequential(\n","            nn.Linear(transformer_hidden_dim, clf_linear_dim, device=device),\n","            nn.Dropout(dropout),\n","            nn.ReLU(),\n","            nn.Linear(clf_linear_dim, num_classes, device=device)\n","        )\n","    \n","    def forward(self, x: ndl.Tensor) -> ndl.Tensor:\n","        encoded_state = self.encoder(x)  # batch_size x seq_len x hidden_dim\n","        encoded_state_first = ops.split(encoded_state, axis=1)[0]  # batch_size x hidden_dim\n","        clf_output = self.classificator(encoded_state_first)  # batch_size x num_classes\n","        return clf_output\n","    \n","    @staticmethod\n","    def _softmax(x: np.ndarray) -> np.ndarray:\n","        \"\"\"\n","        Numpy softmax for predicting label indices.\n","        \"\"\"\n","        e_x = np.exp(x - x.max(axis=-1, keepdims=True))\n","        return e_x / e_x.sum(axis=-1, keepdims=True)\n","    \n","    def get_labels_from_logits(self, x: ndl.Tensor) -> np.ndarray:\n","        return self._softmax(x.detach().numpy()).argmax(axis=-1)\n","    \n","    def predict(self, x: ndl.Tensor) -> np.ndarray:\n","        \"\"\"\n","        Predict label indices.\n","        \"\"\"\n","        self.eval()\n","        out = self.forward(x)\n","        return self.get_labels_from_logits(out)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-RNooxc6yHIP"},"outputs":[],"source":["model = TextClassifier(\n","    num_classes=train_dataset.num_classes,\n","    vocab_size=len(tokenizer),\n","    transformer_max_length=MAX_LENGTH,\n","    \n","    transformer_hidden_dim=64 * 4,\n","    transformer_linear_dim=64 * 4,\n","    transformer_n_layers=3,\n","    transformer_n_heads=4,\n","    \n","    clf_linear_dim=128,\n","    device=DEVICE\n",")"]},{"cell_type":"markdown","source":["## 5. Training\n","\n","Unfortunately, training appeared to be very slow, so in order to demonstrate that the model *actually learns* we will try to overfit with just one batch."],"metadata":{"id":"-AdKluln9VB0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2sNojnOWTlwr"},"outputs":[],"source":["optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","criterion = nn.SoftmaxLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HE24iRPtTlpz"},"outputs":[],"source":["def train_or_evaluate(model, dataloader, criterion, optimizer=None, log_step: int = None) -> Tuple[float, float]:\n","    if optimizer:\n","        model.train()\n","    else:\n","        model.eval()\n","    \n","    losses = []\n","    metrics = []\n","\n","    # TODO: delete for 'real' training\n","    x_, y_ = next(iter(dataloader))\n","\n","    for i, (x, y) in enumerate(tqdm(dataloader)):\n","        if optimizer:\n","            optimizer.reset_grad()\n","        \n","        # TODO: delete for 'real' training\n","        x, y = x_, y_\n","        \n","        out = model(x)\n","        loss = criterion(out, y)\n","\n","        if optimizer:\n","            loss.backward()\n","            optimizer.step()\n","\n","        loss_value = loss.detach().numpy()[0]\n","        losses.append(loss_value)\n","        \n","        labels = model.get_labels_from_logits(out)\n","        metric = accuracy_score(y.detach().numpy(), labels)\n","        metrics.append(metric)\n","\n","        if log_step and i % log_step == 0:\n","            logger.debug(f'batch {i + 1} | mov.avg: loss={np.mean(losses[-log_step:]):.4f}, metric={np.mean(metrics[-log_step:]):.4f}')\n","            logger.debug(f'y_true: {np.array(y.detach().numpy(), dtype=int)}, y_pred: {labels}')\n","        \n","        # TODO: delete for 'real' training\n","        if i == 201:\n","            break\n","\n","    return np.mean(losses), np.mean(metrics)"]},{"cell_type":"markdown","source":["From training logs we can actually see decreasing of training loss (almost to 0.0) and increasing of accuracy score (almost to 1.0):"],"metadata":{"id":"Xxo01_M8gJiU"}},{"cell_type":"code","source":["train_losses, train_metrics, eval_losses, eval_metrics = [], [], [], []\n","\n","for epoch in range(1, EPOCHS + 1):\n","    train_loss, train_metric = train_or_evaluate(model, train_dataloader, criterion, optimizer, log_step=20)\n","    logger.info(f'Epoch: {epoch} / {EPOCHS} | train_loss: {train_loss:.5f} | train_metric: {train_metric:.5f}')\n","\n","    # TODO: uncomment for 'real' training\n","    # eval_loss, eval_metric = train_or_evaluate(model, valid_dataloader, criterion)\n","    # logger.info(f'Epoch: {epoch} / {EPOCHS} | eval_loss: {eval_loss:.5f} | eval_metric: {eval_metric:.5f}')\n","\n","    train_losses.append(train_loss)\n","    train_metrics.append(train_metric)\n","    # eval_losses.append(eval_loss)\n","    # eval_metrics.append(eval_metric)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448,"referenced_widgets":["93f38bbba907458496de6851eb76558c","c50e63a3e2e74980b93ad9b661612174","a137dcf837bd4a109ae0af5be9fc0471","376b49c5a8d94f67beed36a21d033f0e","dfbd1d92369844eb8e3251de826e6f25","968f380941dc4673a9f9e48911e1248e","c73974cff70d43978915155815bcc263","aebc73108e7e4b96b4d8495e9b19da66","4e1b25d12b8648e5a7923d7b7681db8e","280b51e514254d468ec179ea3044ae8f","67e9e26c481d42e98785d9bd12935eca"]},"id":"wmZz5roLbhZv","executionInfo":{"status":"ok","timestamp":1672764728195,"user_tz":-180,"elapsed":2041728,"user":{"displayName":"Дмитрий Шоломицкий","userId":"05073812129486018670"}},"outputId":"f3dae7c2-f813-4710-b945-7921bcf101fb"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93f38bbba907458496de6851eb76558c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2023-01-03 16:18:14.341 | DEBUG    | __main__:train_or_evaluate:35 - batch 1 | mov.avg: loss=0.8860, metric=0.5500\n","2023-01-03 16:18:14.385 | DEBUG    | __main__:train_or_evaluate:36 - y_true: [0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1], y_pred: [1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1]\n","2023-01-03 16:21:35.693 | DEBUG    | __main__:train_or_evaluate:35 - batch 21 | mov.avg: loss=0.9726, metric=0.5300\n","2023-01-03 16:21:35.722 | DEBUG    | __main__:train_or_evaluate:36 - y_true: [0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1], y_pred: [1 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 0 1]\n","2023-01-03 16:24:58.015 | DEBUG    | __main__:train_or_evaluate:35 - batch 41 | mov.avg: loss=0.7295, metric=0.5225\n","2023-01-03 16:24:58.043 | DEBUG    | __main__:train_or_evaluate:36 - y_true: [0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1], y_pred: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n","2023-01-03 16:28:19.885 | DEBUG    | __main__:train_or_evaluate:35 - batch 61 | mov.avg: loss=0.6983, metric=0.5525\n","2023-01-03 16:28:19.887 | DEBUG    | __main__:train_or_evaluate:36 - y_true: [0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1], y_pred: [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n","2023-01-03 16:31:42.719 | DEBUG    | __main__:train_or_evaluate:35 - batch 81 | mov.avg: loss=0.6785, metric=0.5750\n","2023-01-03 16:31:42.721 | DEBUG    | __main__:train_or_evaluate:36 - y_true: [0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1], y_pred: [1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n","2023-01-03 16:35:04.090 | DEBUG    | __main__:train_or_evaluate:35 - batch 101 | mov.avg: loss=0.6421, metric=0.6125\n","2023-01-03 16:35:04.141 | DEBUG    | __main__:train_or_evaluate:36 - y_true: [0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1], y_pred: [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","2023-01-03 16:38:26.104 | DEBUG    | __main__:train_or_evaluate:35 - batch 121 | mov.avg: loss=0.2968, metric=0.8775\n","2023-01-03 16:38:26.154 | DEBUG    | __main__:train_or_evaluate:36 - y_true: [0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1], y_pred: [1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1]\n","2023-01-03 16:41:47.606 | DEBUG    | __main__:train_or_evaluate:35 - batch 141 | mov.avg: loss=0.2538, metric=0.9000\n","2023-01-03 16:41:47.614 | DEBUG    | __main__:train_or_evaluate:36 - y_true: [0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1], y_pred: [0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 1]\n","2023-01-03 16:45:10.605 | DEBUG    | __main__:train_or_evaluate:35 - batch 161 | mov.avg: loss=0.0535, metric=0.9825\n","2023-01-03 16:45:10.610 | DEBUG    | __main__:train_or_evaluate:36 - y_true: [0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1], y_pred: [0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1]\n","2023-01-03 16:48:33.530 | DEBUG    | __main__:train_or_evaluate:35 - batch 181 | mov.avg: loss=0.2393, metric=0.9100\n","2023-01-03 16:48:33.532 | DEBUG    | __main__:train_or_evaluate:36 - y_true: [0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1], y_pred: [0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0]\n","2023-01-03 16:51:56.640 | DEBUG    | __main__:train_or_evaluate:35 - batch 201 | mov.avg: loss=0.0840, metric=0.9625\n","2023-01-03 16:51:56.643 | DEBUG    | __main__:train_or_evaluate:36 - y_true: [0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1], y_pred: [0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1]\n","2023-01-03 16:52:06.914 | INFO     | __main__:<module>:5 - Epoch: 1 / 1 | train_loss: 0.46464 | train_metric: 0.74282\n"]}]},{"cell_type":"markdown","source":["## 6. Save/load\n","\n","Challenge for making `needle` object serializable was to persist `BackendDevice` and `NDArray`.\n","\n","In `BackendDevice` we save only device's name during serialization and then recreate device from corresponding function call during deserialization:\n","```python\n","class BackendDevice:\n","    def __getstate__(self):\n","        return {'name': self.name}\n","\n","    def __setstate__(self, state):\n","        devices = {'cpu': cpu, 'cuda': cuda, 'cpu_numpy': cpu_numpy}\n","        self.__dict__ = devices[state['name']]().__dict__.copy()\n","```\n","\n","In `NDArray` we convert numeric data into `numpy`-array during serialization and then create `NDArray` from `numpy`-array during deserialization:\n","```python\n","class NDArray:\n","    def __getstate__(self):\n","        attributes = self.__dict__.copy()\n","        attributes['_handle'] = self.numpy()\n","        return attributes\n","\n","    def __setstate__(self, state):\n","        state['_handle'] = NDArray(state['_handle'], device=state['_device'])._handle\n","        self.__dict__ = state\n","```\n","\n","Another nuance: we need to clean `Tensor`'s `grad` before dumping, otherwise Python raises recursion error.\n","\n","After these upgrades we can use simple `pickle.dump` & `pickle.load` in `needle.utils.save` & `needle.utils.load`:\n","\n","```python\n","def save(obj, filepath: Union[str, Path]):\n","    \"\"\"\n","    Save needle object to a file\n","    (tensor's gradients will be set as None).\n","    \"\"\"\n","    if isinstance(obj, ndl.nn.Module):\n","        for param in obj.parameters():\n","            param.grad = None\n","    elif isinstance(obj, ndl.Tensor):\n","        obj.grad = None\n","    with open(filepath, 'wb') as file:\n","        pickle.dump(obj, file)\n","\n","\n","def load(filepath: Union[str, Path]):\n","    \"\"\"\n","    Load needle object from a file \n","    (object will be put on the same device they were before being saved to a file).\n","    \"\"\"\n","    with open(filepath, 'rb') as file:\n","        return pickle.load(file)\n","```"],"metadata":{"id":"W7_n66HxOOfD"}},{"cell_type":"markdown","source":["Predictions of the model and true labels:"],"metadata":{"id":"aqkjWe6NOUZ8"}},{"cell_type":"code","source":["true_labels = np.array(batch_y.detach().numpy(), dtype=int)\n","model_predictions = model.predict(batch_x)\n","\n","print(model_predictions, true_labels)"],"metadata":{"id":"liPwLoF2ORCh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672764800739,"user_tz":-180,"elapsed":439,"user":{"displayName":"Дмитрий Шоломицкий","userId":"05073812129486018670"}},"outputId":"31e4d414-50a3-4389-a86e-f0b635d3d09c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1] [0 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1]\n"]}]},{"cell_type":"markdown","source":["Save model as file:"],"metadata":{"id":"-W424FXpOZo1"}},{"cell_type":"code","source":["ndl.save(model, 'model.ndl')"],"metadata":{"id":"07ZWEtzip1-M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! du -h model.ndl"],"metadata":{"id":"5RzWTE7ZUpQG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672765863300,"user_tz":-180,"elapsed":438,"user":{"displayName":"Дмитрий Шоломицкий","userId":"05073812129486018670"}},"outputId":"ebf333b7-4896-45aa-91fc-b20042801f70"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["15M\tmodel.ndl\n"]}]},{"cell_type":"markdown","source":["Dumpled model is also available in repository's folder `assets/`. \n","\n","Restore model and make predictions:"],"metadata":{"id":"7Y8W1rNMOgKq"}},{"cell_type":"code","source":["model_restored = ndl.load('model.ndl')\n","\n","model_restored_predictions = model_restored.predict(batch_x)\n","\n","print(f'model_restored_predictions: {model_restored_predictions}')\n","print(f'predictions are the same as before dumping: {(model_predictions == model_restored_predictions).all()}')"],"metadata":{"id":"F9flw08vkQ7o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672766082360,"user_tz":-180,"elapsed":1137,"user":{"displayName":"Дмитрий Шоломицкий","userId":"05073812129486018670"}},"outputId":"9ac03a3b-58b6-4234-bf36-8db1df9fa9c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["model_restored_predictions: [0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1]\n","predictions are the same: True\n"]}]},{"cell_type":"code","source":["# TODO: uncomment after 'real' training\n","\n","# texts = [\n","#     \"I don't like this movie at all. Poor acting, boring story... No wonder that box office is low!\",\n","#     \"This movie is fantastic, I really enjoyed it! Great actors, good operator's work, beautiful music! This director became my favourite!\"\n","# ]\n","# texts_tensor = ndl.Tensor([tokenizer(line, MAX_LENGTH) for line in texts], device=DEVICE)\n","# preds = model_restored.predict(texts_tensor)\n","# print(f'preds: {preds}')\n","# print('labels:')\n","# for pred in preds:\n","#     print(train_dataset.index2label[pred])"],"metadata":{"id":"Y-cMA9AjjqBC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672766094771,"user_tz":-180,"elapsed":658,"user":{"displayName":"Дмитрий Шоломицкий","userId":"05073812129486018670"}},"outputId":"fb3bfb72-9860-440b-f549-3152406a2e2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["preds: [0 0]\n","labels:\n","negative\n","negative\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"NB60fc1Djp52"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNhHZ5X0J0XiwaOHLiYBO1R"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"93f38bbba907458496de6851eb76558c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c50e63a3e2e74980b93ad9b661612174","IPY_MODEL_a137dcf837bd4a109ae0af5be9fc0471","IPY_MODEL_376b49c5a8d94f67beed36a21d033f0e"],"layout":"IPY_MODEL_dfbd1d92369844eb8e3251de826e6f25"}},"c50e63a3e2e74980b93ad9b661612174":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_968f380941dc4673a9f9e48911e1248e","placeholder":"​","style":"IPY_MODEL_c73974cff70d43978915155815bcc263","value":" 10%"}},"a137dcf837bd4a109ae0af5be9fc0471":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_aebc73108e7e4b96b4d8495e9b19da66","max":2000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e1b25d12b8648e5a7923d7b7681db8e","value":201}},"376b49c5a8d94f67beed36a21d033f0e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_280b51e514254d468ec179ea3044ae8f","placeholder":"​","style":"IPY_MODEL_67e9e26c481d42e98785d9bd12935eca","value":" 201/2000 [34:01&lt;5:12:40, 10.43s/it]"}},"dfbd1d92369844eb8e3251de826e6f25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"968f380941dc4673a9f9e48911e1248e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c73974cff70d43978915155815bcc263":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aebc73108e7e4b96b4d8495e9b19da66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e1b25d12b8648e5a7923d7b7681db8e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"280b51e514254d468ec179ea3044ae8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67e9e26c481d42e98785d9bd12935eca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}